
### 写在前面
- 书籍介绍：暂无。
- 我的简评：暂无。
- ！！福利：文末有书籍地址、笔记思维导图、相关资料下载地址哦

### 第1章  开发环境配置

#### 1、操作系统的选择

#### 2、练习平台Steamboat

#### 3、第三方库的安装

#### 4、常用软件的安装

#### 5、深度学习环境配置

#### 6、Node.js环境配置

### 第2章 Web网站的构成和页面渲染

#### 1、nginx服务器

#### 2、浏览器

#### 3、网络协议

### 第3章  爬虫与反爬虫

#### 1、动态网页与网页源代码

#### 2、爬虫知识回顾

#### 3、反爬虫的概念与定义

### 第4章 信息校验型反爬虫

- 信息校验中的“信息”指的是客户端发起网络请求时的请求头和请求正文，而“校验”指的是服务器端通过对信息的正确性、完整性或唯一性进行验证或判断

- 服务器通过校验请求头或者请求正文中特定的信息，就可以区分正常用户和爬虫程序了

#### 1、User-Agent反爬虫

- 1.User-Agent反爬虫指的是服务器端通过校验请求头中德UserAgent值来区分正常用户和爬虫程序的手段

- 2.User-Agent就是请求头域之一，服务器能够从User-Agent对应的值中识别客户端使用的操作系统、CPU类型、浏览器引擎、操作系统语言等

- 3.User-Agent头域并非不可缺少，而且它的值可以被更改

- 4.只要请求头中的User-Agent头域值包含黑名单中德关键词，那么这个请求就无法通过校验

#### 2、Cookie反爬虫

- 1.Cookie反爬虫指的是服务器端通过校验请求头中的Cookie值来区分正常用户和爬虫程序的手段

- 2.Cookie不仅可以用于Web服务器的用户身份信息存储或状态保持，还能够用于反爬虫

- 3.服务器会校验每个请求头中的Cookie值是否符合规则，如果通过校验，则返回正常资源，否则将请求重定向到首页

- 4.除了反爬虫外，重定向和Cookie常常被用来指定网站的入口或提高访问门槛

- 5.User-Agent和Cookie都是请求头的默认头域，在值的设定方面有一定的局限性，但是与JavaScript结合后，就会变得很灵活

#### 3、签名验证反爬虫

- 1.签名是根据数据源进行计算或加密的过程，签名的结果是一个具有惟一性和一致性的字符串

- 2.与Cookie、User-Agent、Host和Referer等请求头域不同，用于签名验证的信息通常被放在请求正文中发送到服务器端

- 3.签名验证有很多实现方式，但原理都是相同的：由客户端生成一些随机值和不可逆的MD5加密字符串，并在发起请求时将这些值发送给服务器端。服务器端使用相同的方式对随机值进行计算以及MD5加密，如果服务器端得到的MD5与前端提交的MD5值相等，就代表正常请求，否则返回403

- 4.时间戳可以有效的避免请求正文被复用，组合字符串的消息摘要则用于避免服务器端处理被篡改过的数据

- 5.签名验证反爬虫被广泛应用于Web领域，当发现请求正文中包含消息摘要值（特别是32位随机字符串）时，就可以大胆猜测目标网站使用了签名验证反爬虫

#### 4、WebSocket握手验证反爬虫

- 1.所有基于HTTP协议的反爬虫都可以用在WebSocket协议上

- 2.客户端按照WebSocket规范生成握手信息并向服务器端发送握手请求，然后读取服务器端推送消息，最后验证握手结果

#### 5、WebSocket消息验证反爬虫

- 1.WebSocket只需要完成一次握手，就可以保持长期连接，在后续的消息互发阶段是不需要用到HTTP协议的

- 2.其实消息互发阶段也是可以对客户端身份进行校验的，这是因为客户端所获取的消息是由服务器端主动推送的

#### 6、WebSocket Ping反爬虫

- 1.WebSocket协议规范中约定，服务器端可以向客户端发送Ping帧，当客户端收到Ping帧时应当回复Pong帧。如果客户端不回复或者回复的并不是Pong帧，那么服务器端就可以认为客户端异常，主动关闭该连接

- 信息校验主要解决了客户端身份鉴别、数据来源判断和请求的合法性判断等问题，避免数据接收者使用篡改过的数据，保证数据的有效性

### 第5章 动态渲染反爬虫

#### 1、常见的动态渲染反爬虫案例

- 1.动态渲染被广泛应用在Web网站中，大部分网站会使用JavaScript来提升用户体验

#### 2、动态渲染的通用解决办法

- 1.确实有很多的渲染工具可以满足动态网页爬取需求，其中最常用的是Puppeteer、Splash和Selenium

- 2.Selenium是一个用于测试Web应用程序的工具，可以通过Selenium和浏览器驱动调用浏览器执行特定的操作，如发起请求、点击操作、鼠标下滑等

- 3、使用Python中德异步库来编写爬虫时，Selenium就不是那么适合了。Puppeteer是一个能够做到与Selenium套件相同工作并且支持异步的渲染工具

- 4.Splash是一个异步的JavaScript渲染服务，它是带有HTTP API的轻量级Web浏览器，能够并行的处理多个页面请求，在页面上下文中执行自定义的JavaScript以及模拟浏览器中德点击、下滑等操作

- 5.Splash返回3种不同类型的结果：页面截图、资源加载信息和HTML文本

- 6.Splash命令框使用的并不是Python语言，而是Lua语言

- 7.渲染工具知识扩展：Selenium套件通过驱动浏览器执行操作，本质上使用浏览器；Puppeteer实际上通过API控制Chromium或Chrome浏览器；Splash基于开源的浏览器引擎WebKit

- 使用渲染工具时，不仅要考虑渲染性能，还需要关注页面渲染质量

### 第6章 文本混淆反爬虫

- 文本混淆可以有效的避免爬虫获取Web应用中重要的文字数据，使用文本混淆爬虫获取文字数据的方法称为文本混淆反爬虫

- 常见的文本混淆手段有图片伪装、文字映射和自定义字体等

#### 1、图片伪装反爬虫

- 1.常见的电话并不是一串数字，而是一张图片

- 2.光学字符识别是应对图片伪装反爬虫的最佳选择

#### 2、CSS偏移反爬虫

- 1.CSS偏移反爬虫指的是利用CSS样式将乱序的文字排版为人类正常阅读顺序的行为

- 2.实际上并不是我们的逻辑和代码有错，而是页面显示错误

- 3.CSS样式可以改变页面显示，但这种“改变”仅存在于浏览器（能够解释CSS的渲染工具）中

#### 3、SVG映射反爬虫

- 1.利用SVG实现的反爬虫手段用矢量图形代替具体的文字，不会影响用户正常阅读，但爬虫程序无法像读取文字那样获得SVG图形中的内容

- 2.映射关系不可能凭空出现，一定使用了某种技术特性

- 3.SVG映射反爬虫利用了浏览器与编程语言在渲染方面的差异，以及SVG与CSS定位这样的前端知识

#### 4、字体反爬虫

- 1.从网页源代码中看到的并不是符号，而是由&#X开头的一些字符

- 2.字体文件中不仅包含字形数据和点信息，还包括字符到字形映射、字体标题、命名和水平指标等

- 3.只有起止坐标和点坐标数据完全相同的字形，描述的才是相同字符

- 4.如果开发者频繁改动字体文件或者准备多套字体文件并随机切换，那真是一件头疼的事

- 5.绕过系列工作：准备基准字形描述信息；访问目标网页；从目标网页中读取字体编码字符；下载WOFF文件并用Python代码打开；根据字体编码字符找到WOFF文件中的字形轮廓信息；将该自行轮廓信息与基准字形轮廓信息进行对比；得出对比结果；

#### 5、文本混淆反爬虫通用解决方法

- 1.实际上我们可以根据需求将页面中所需的部分数据截图保存，然后再用光学字符识别的手段从截图中提取文字

- 2.PyTesseract库并非屡试不爽，他能够精确的识别没有干扰信息、轮廓清晰的数字，但对于模糊、有干扰因素的图片以及汉字的识别率就很低了

- 3.还可以借助第三方的力量，使用识别率高的API

- 4.收费的文字识别API的准确率和识别能力都超过免费开源的第三方库PyTesseract

- 主动型反爬虫，即使借助渲染工具也无法获得目标数据，那正确的做法：探寻反爬虫原理，用代码实现对应的算法或逻辑

### 第7章 特征识别反爬虫

- 特征识别反爬虫是指通过客户端的特征、属性或用户行为特点来区分正常用户和爬虫程序的手段

#### 1、WebDriver识别

- 1.使用Navigator对象的webDriver属性来判断客户端是否通过webDriver驱动浏览器

- 2.navigator.webdriver只适用于使用WebDriver的渲染工具，对于Splash这种使用WebKit内核开发的渲染工具来说是无效的

- 3.WebDriver检测的结果有3种，分别是true、false和undefined

- 4.由于navigator.webdriver值允许被改变，所以这种检测方法并不可靠

#### 2、浏览器特征

- 1.除了Navigator对象的userAgent、cookieEnable、platform、plugins等属性外，Screen对象的一些属性也可以作为判断依据

- 2.事实上，只要有可能出现不同结果的属性，就可以作为客户端特性

- 3.属性值作为特征并不代表服务器端通过单个属性值就能确认客户端身份，他们只是服务器端判断客户端身份的依据之一

#### 3、爬虫特征

- 1.正常用户浏览网页的频率不会像爬虫程序那么高，开发者可以将访问频率过高的客户端视为爬虫程序

- 2.面对根据IP地址实现的访问频率限制反爬虫，我们可以使用多台机器共同爬取

- 3.要限制爬虫程序的请求频率，首先要找到并确定客户端的身份标识，然后根据标识记录该客户端的请求次数，并且拒绝单位时间内请求次数过多的客户端请求

- 4.使用nginx实现根据IP地址限制爬虫访问频率的功能

- 5.浏览器指纹也成为客户端指纹，是指由多种客户端特征信息组成的字符串结果。组成浏览器指纹的特征信息包括硬件信息（如屏幕的分辨率和色值、CPU的核心数与类型等）、浏览器信息（插件列表和User-Agent属性值等）和不可重复信息（如IP地址、已登录用户的cookie等）

- 6.不同浏览器一般使用不同的图像处理引擎、图像导出选项、图像压缩级别，即使是使用相同的绘制代码，得出的结果也会有所不同

- 7.单一的Canvas指纹、WebGL指纹和Navigator对象属性都不能作为客户端的身份标识，但将这些指纹与属性值组合在一起，就能够降低指纹重复的概率

- 8.限制客户端访问频率的前提是找到能够代表客户端身份的特征

#### 4、隐藏链接反爬虫

- 1.隐藏链接反爬虫指的是网页中隐藏用于检测爬虫程序的链接的手段。被隐藏的链接不会显示在页面中，正常用户无法访问，但爬虫程序有可能将该链接放到待爬队列，并向该链接发起请求

- 2.因为客户端的IP地址会随着网络的关闭与开启而变化，所以在实际应用中，为了避免误伤到正常用户，IP的封禁并不会持续很久

### 第8章 App反爬虫

#### 1、App抓包

#### 2、APK文件反编译

#### 3、代码混淆反爬虫

#### 4、App应用加固知识扩展

#### 5、了解应用程序自动化测试工具

### 第9章 验证码

- 验证码可以有效防止恶意注册、刷票、论坛灌水等有损网站利益的行为

- 常见的验证码有滑动验证码、拼图验证码和文字点选验证码

#### 1、字符验证码

- 1.字符验证码指用数字、字母、汉字和标点符号等字符作为元素的图片验证码

- 2.在实际应用中，图片验证码的识别成功率达到75%才能满足爬虫工程师的需求

- 3.深度学习是机器学习研究中的一个新领域，动机在于建立能够模拟人脑进行分析学习的神经网络，希望模仿人脑的机制来解释数据，例如图像、声音和文本

- 4.卷积神经网络中常见的概念有输入层、图片数字化处理、卷积层、卷积运算、池化层、全连接层和输出层等

- 5.添加了干扰信息的字符验证码可以有效增加识别难度和错误率。除了斜线和噪点外，还可以使用字符扭曲、角度旋转和文字重叠等方法

#### 2、计算型验证码

- 1.在字符验证码的基础上增加了数学运算

#### 3、滑动验证码

- 1.计算机难以准确的完成鼠标按下、拖拽、释放等行为

- 2.滑动验证码的校验依据和实现过程，其中通过校验的关键时滑块的移动距离

#### 4、滑动拼图验证码

- 1.滑动拼图验证码在滑动验证码的基础上增加了随机滑动距离，用户需要使用滑动的方式完成拼图，才能通过校验

- 2.可以将没有缺口的图片与有缺口的图片进行对比，通过一定的技术手段判断缺口的位置，从而计算出滑块所需移动的距离

- 3.滑动拼图验证码分为滑动和拼图两个部分，滑动需要用到人类的行为，而拼图需要用到人类的视觉

#### 5、文字点选验证码

- 1.通过文字点选验证码校验的关键是找到图片中文字的具体位置

- 2.目标检测是深度学习领域的一个研究方向，常见的应用有人脸识别、自动驾驶等

- 3.计算机要想通过验证，必须完成读懂要求、目标位置检测、文字识别和点击等操作

- 4.点选验证码的关键是目标定位和识别

#### 6、鼠标轨迹的检测和原理

- 1.鼠标从页面某个位置移动到按钮上的路线是无限多的

#### 7、验证码产品赏析

- 1.滑动验证码：腾讯滑动验证码、极验滑动验证码、网易易盾滑动拼图验证码、顶象滑动拼图验证码

- 2.图标验证码：螺丝帽图标点选验证码、网易易盾图标点选验证码、极验图标点选验证码、天验图标路径验证码

- 3.空间推理验证码：腾讯空间验证码、极验空间推理验证码

### 第10章 综合知识

#### 1、编码与加密

- 字符集是指各国家的文字、标点符号、图形符号和数字等字符的集合

- ASCII是基于拉丁字母表的一套计算机编码系统，主要用于显示现代英语和其他西欧语言

- ASCII的RFC文档编码为20，其中约定了ASCII的使用范围、标准码、字符表示和代码识别等内容

- ASCII码默认使用7位二进制数来表示所有的大写字母、小写字母、数字（0-9）、标点符号和特殊的控制符

- Base64的RFC文档编码为4648，它约定了Base16、Base32和Base64的编码规范和计算方法

- 有经验的爬虫工程师看到带有“==”符号或者“=”符号的字符串时，自然会认为这是Base64编码字符串后得到的结果

- Base64编码和解码时都是将原本8位的二进制数转换成6位的二进制数

- MD5消息摘要算法是一种被广泛使用的散列函数，能够将任意长度的消息转换成128位的消息摘要

- MD5的RFC文档编码为1321，约定了一些术语和符号，并描述了MD5算法的计算步骤和方法

- MD5的典型应用场景就是一致性验证，如文件一致性和信息一致性

- MD5在此场景下的作用是验证下载后得文件是否与服务器端文件一致，及时发现文件缺失现象

- MD5算法具有“不可逆”和“压缩”这两种特性，而MD5算法输出的值则具有“不可读”的特性，这也使得其成为密码保存的不二之选

- MD5是消息摘要算法中德一种，同样计算消息摘要的算法还有SHA1和SHA256等

- 加密和解密时使用同一个密钥的加密方式叫做对称加密，使用不同密钥的是非对称加密

- 对称加密的速度更快，速度的优势使得它更适合大量数据加密的场景。常见的对称加密算法有DES、3DES、BLOWFISH、RC5和AES等

- 大部分编程语言有成熟的AES库，如JavaScript语言的CryptoJS库，python语言的pycrypto库

- 与对称加密不同的是，非对称加密方式需要两个密钥：公钥和私钥

- 在非对称加密算法中，应用最广泛、强度最高的是RSA算法

- 在学习RSA算法的原理之前，需要了解一些数学概念，如质数、互质关系、欧拉函数、欧拉定理和模反元素

- 无论是Base64编码、消息摘要算法MD5还是加密算法，都使用一定的计算规则将一串字符转换成不可读的另一串字符

- 不可逆的消息摘要算法常用于签名，而可逆的对称加密算法AES和非对称加密算法RSA通常用于保护数据

#### 2、JavaScript代码混淆

- 常用的混淆方法有正则替换、代码编码和代码复杂化等

- 正则替换之变量名替换：短字母替换变量名，增加空格和换行符的删除操作

- 正则替换之进制替换：浏览器能解析Base64编码，还能解析十六进制的字符

- 代码编码之Base64：浏览器会自动解析Base64的编码

- 代码编码之AAEncode：能将JavaScript代码转换为颜文字

- 代码编码之JJEncode：将代码转换为"$"、"_"、"+"符号

- 代码复杂化之访问符：改变对象访问符

- 代码复杂化之Packer：将原代码变得复杂，降低可读性

- 抽象语法树AST是源代码语法结构的一种抽象表示，是编译器分析和理解语法的基础

- JavaScript编译器的目的是将JavaScript代码编译为机器码，而混淆器的处理结果仍然是JavaScript代码

- UglifyJS实现对代码的分析和对语法树的修改，并输出混淆结果。UglifyJS提供了用于分析词法和词法语义的解析模块parse、代码生成模块codegen和语法树遍历模块transform等

#### 3、前端禁止事件

- 开发者可以通过禁用F12键和鼠标右键来达到预防爬虫工程师分析网页的目的

#### 4、法律法规

- Robots协议是网站跟爬虫程序之间的协议。网站经营者可以通过Robots协议告知爬虫程序可爬取的范围和禁止爬取的范围

- 用技术手段绕过经营者网站的反爬措施属于违法行为


### 写在后面
- pdf书籍、笔记思维导图、资料打包下载地址：暂无
- 思维导图在线查看：[点击打开](/bigdata_notes/attachment/C.《Python3反爬虫原理与绕过实战》.svg)
- 得到电子书地址：暂无